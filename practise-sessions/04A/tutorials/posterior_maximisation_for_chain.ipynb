{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Posterior maximisation for a Markov chain\n",
    "\n",
    "Consider a Markov chain with nodes $X_1,\\ldots, X_n$ and with some evidence. Then we can ask what is the assignment $x_1,\\ldots,x_n$ that maximises the posterior $\\Pr[x_1,\\ldots,x_n|\\text{evidence}]$ provided that the parameters of the chain are fixed.\n",
    "\n",
    "<img src = 'illustrations/chain-max-i.png' width=100%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Example\n",
    "\n",
    "Let the evidence be observation $x_n=1$. Then we can express\n",
    "\n",
    "\\begin{align}\n",
    "\\Pr[x_1,\\ldots,x_n|evidence]&=\\Pr[x_1,..., x_{n-1},x_n|x_n=1]\n",
    "\\end{align}\n",
    "\n",
    "From which we can trivially conclude that  \n",
    "\n",
    "\\begin{align}\n",
    "\\Pr[x_1,\\ldots,x_n|evidence]&=\n",
    "\\begin{cases}\n",
    "\\Pr[x_1,..., x_{n-1},x_n=1], &\\text{if } x_n=1\\\\\n",
    "0 &\\text{if }x_n\\neq 1,\\\\\n",
    "\\end{cases}\n",
    "\\end{align}\n",
    "\n",
    "Let us now consider the interesting case\n",
    "\n",
    "\\begin{align*}\n",
    "\\Pr[x_1,..., x_{n-1},x_n=1]&= \\Pr[x_1,..., x_{n-1}]\\cdot \\Pr[x_n=1|x_{n-1}]\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "We have to maximise this over $x_1,..x_{n-1}$ for fixed initail probabilities and transition probabilities\n",
    "\n",
    "\\begin{align}\n",
    "\\Pr[x_1,..., x_{n-1}, x_n|evidence]&=\\Pr[x_1,..., x_{n-1}]\\cdot \\Pr[x_n=1|x_{n-1}]=\n",
    "\\Pr[x_1]\\cdot \\Pr[x_2|x_{1}]\\cdots \\Pr[x_n=1|x_{n-1}]\\to \\max\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "This is combinatorial onptimisation task which can be solved by complete traversal of all options. \n",
    "Fortunately, we can simplify the task\n",
    "\n",
    "\\begin{align}\n",
    "\\Pr[x_1,..., x_{n-1},x_n=1]&=\\left(\\max_{x_1,\\ldots, x_{n-2}} \\Pr[x_1,..., x_{n-1}]\\right)\\cdot \\Pr[x_n=1|x_{n-1}]\\to \\max\n",
    "\\end{align}\n",
    "\n",
    "into two separate minimisation tasks. The process can be repeated for $x_1,\\ldots,x_{n-1}$ and so on. \n",
    "\n",
    "As a result the the computational complexity becomes tractable. This forms the basis of general posterior maximisation algorithm aka Viterbi algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Connection to minimal path search\n",
    "\n",
    "As usual we can simplify the maximisation task by lookin log-posterior. Then the product becomes to a sum where all terms are negative. Thus we can reverse the the maximisation task to a minimisation task\n",
    "\n",
    "\\begin{align}\n",
    "-\\log\\Pr[\\boldsymbol{x}|evidence]&=-\\log\\Pr[x_1]-\\log\\Pr[x_2|x_{1}]-\\cdots-\\log\\Pr[x_n=1|x_{n-1}]\\to \\min\n",
    "\\end{align}\n",
    "\n",
    "The latter can be solved by finding a minimum path from the starting point to the end point."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
