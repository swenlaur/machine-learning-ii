{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Posterior derivation for dice throwing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Likelihood function for dice and multinomial distribution\n",
    "\n",
    "The number of outcomes is the main difference between the coin-throws and dice throwing. Therefore, we need to fix probabilities for each potential outcome:\n",
    "\n",
    "\\begin{align}\n",
    "p[i]=p_i \n",
    "\\end{align}\n",
    "\n",
    "such that\n",
    "\n",
    "\\begin{align}\n",
    "p_1+\\cdots p_m=1\\enspace.\n",
    "\\end{align}\n",
    "\n",
    "It is easy to assign probability for the configuration where we first get $k_1$ ones, $k_2$ twos and so on\n",
    "\n",
    "\\begin{align}\n",
    "\\Pr[1,\\ldots,1,2\\ldots,2\\ldots,m,\\ldots,m]= p_1^{k_1}p_2^{k_2}\\ldots p_m^{k_m}\\enspace.\n",
    "\\end{align}\n",
    "\n",
    "Note that any sequence of observation that has $k_1$ ones, $k_2$ twos and so on has the same probability. Therefore\n",
    "\n",
    "\\begin{align}\n",
    "p[k_1,k_2,\\ldots,k_m|p_1,p_2,\\ldots,p_m]&= Number\\_of_configuration(k_1,k_2,\\ldots,k_m)\\cdot p_1^{k_1}\\cdot p_2^{k_2} \\cdots p_m^{k_m}\\\\\n",
    "&\\propto  p_1^{k_1}\\cdots p_m^{k_m}\\enspace\n",
    "\\end{align}\n",
    "\n",
    "where the exact number of configurations is not relevant as this is fixed by the observations and does not vary if we change unknown parameters $p_1,\\ldots,p_m$.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Maximum likelihood estimation\n",
    "\n",
    "Let us again consider uniformative prior that does not prefer any paramter complect\n",
    "\n",
    "\\begin{align}\n",
    "p[p_1,p_2,\\ldots,p_m]\\propto 1\n",
    "\\end{align}\n",
    "\n",
    "Then the corresponding uninformed posterior is\n",
    "\\begin{align}\n",
    "p[p_1,p_2,\\ldots,p_m|k_1,k_2,\\ldots,k_m]&\\propto  p_1^{k_1}\\cdots p_m^{k_m}\\enspace.\n",
    "\\end{align}\n",
    "\n",
    "To find the parameter assignment that maximises posterior we need to solve optimisation task\n",
    "\n",
    "\\begin{align}\n",
    "F = p_1^{k_1}\\cdots p_m^{k_m}\\to \\max\n",
    "\\end{align}\n",
    "\n",
    "subject to \n",
    "\n",
    "\\begin{align}\n",
    "p_1+p_2+\\cdots+p_m=1\\enspace.\n",
    "\\end{align}\n",
    "\n",
    "Again we can solve the simpler task \n",
    "\n",
    "\\begin{align}\n",
    "\\log F = k_1\\log(p_1)+ \\cdots+k_m\\log(1-p_1-\\cdots p_{m-1})\\to \\max\n",
    "\\end{align}\n",
    "\n",
    "subject to \n",
    "\n",
    "\\begin{align}\n",
    "p_1+p_2+\\cdots+p_m=1\\enspace.\n",
    "\\end{align}\n",
    "\n",
    "instead. Taking partial derivatives and equating them with zero leads to equations\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\partial \\log F}{\\partial p_i} = \\frac{k_i}{p_i} -  \\frac{k_m}{1-p_1-\\cdots p_{m-1}}\n",
    "=\\frac{k_i(1-p_1-\\cdots- p_{m-1})- k_mp_i}{p_i(1-p_1-\\cdots p_{m-1})}=0\n",
    "\\end{align}\n",
    "\n",
    "This is a system of linear equations\n",
    "\n",
    "\\begin{align}\n",
    "k_i = k_i(p_1+\\cdots+ p_{m-1})+ k_mp_i,\\qquad i=1,\\ldots, m-1\n",
    "\\end{align}\n",
    "\n",
    "which has a solution\n",
    "\n",
    "\\begin{align}\n",
    "p_i=\\frac{k_i}{k_1+\\cdots+k_m}\n",
    "\\end{align}\n",
    "\n",
    "that coincides with the classical probility formula."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same formula can be derived through an unconstrained optimisation task combining log-likehood trick with the trick of Lagrange multipliers\n",
    "\n",
    "\\begin{align}\n",
    "F^{*}(p_1,\\ldots,p_m,\\lambda)= log F(p_1,\\ldots, p_m)+\\lambda (p_1+\\cdots+ p_m-1)\\to \\max\\enspace.\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Reduction to coinflipping\n",
    "\n",
    "We can always turn the dice into a coin by declaring $\\text{Heads}=[\\text{Dice}=i]$. By construction\n",
    "\n",
    "\\begin{align}\n",
    "\\Pr[\\text{Heads}]=p_i\n",
    "\\end{align}\n",
    "\n",
    "After that we can reuse all the derivations for the coin-flipping and get formulae for informed and uniformed posteriors. In particular, we get that maximum aposteriori estimate for uninformed person is  \n",
    "\n",
    "\\begin{align}\n",
    "p_i=\\frac{k_i}{k_1+\\cdots+ k_m}\\enspace.\n",
    "\\end{align}\n",
    "\n",
    "However, it turns out that the result is incorrect as uninformed prior to coin-flipping is uniform while the same marginal prior for dice is different. In partticular, there is only one option to define $p_i=1$ while there are meny ways to define $p_i=1$: we just have to satisfy $p_1+\\cdots+p_{i-1}+p_{i+1}+\\cdots + p_m=1$. As a result, uniformed marginal prior for $p_i$ is not constant:\n",
    "\n",
    "\\begin{align}\n",
    "p[p_i=0]&>0\\\\\n",
    "p[p_i=1]&=0\n",
    "\\end{align}\n",
    "and or derivation through coinflipping is incorrect. To be precise, the posterior is a valid paosterior but it does not correspond to conclusions of uniformed person rather to a person that prefers solution $p_i=1, p_j=0$ to other parameter combinations. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
