{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dual representation of Markov random fields\n",
    "\n",
    "Markov random fields (MRFs) are quite good models for image textures as they naturally model local dependencies.\n",
    "\n",
    "<img src = 'illustrations/markov-random-field-i.png' width=100%>\n",
    "\n",
    "\n",
    "The celebrated Hammersley-Clifford theorem fixes the format in which the corresponding probability distribution must be sought:\n",
    "\n",
    "\\begin{align*}\n",
    "p[\\boldsymbol{x}|\\omega]=\\frac{1}{Z(\\omega)}\\cdot\\exp\\Biggl(-\\sum_{c\\in\\textsf{MaxClique}}\\Psi_c(\\boldsymbol{x}_c,\\omega)\\Biggr) \n",
    "\\end{align*} \n",
    "where \n",
    "* $\\omega$ is the set of model parameters\n",
    "* $Z(\\omega)$ is a normalising constant\n",
    "* $\\textsf{MaxClique}$ is the set of maximal cliques in the Markov random field\n",
    "* $\\Psi_c$ is defined on the variables $x_i$ in the clique $c$ \n",
    "\n",
    "In the following we show that this formalisation leads to multivariate normal distribution. We explore how this formalisation is connected to pixel prediction formalisation in the notebook [02_texture_synthesis.ipynb](./02_texture_synthesis.ipynb). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import sys\n",
    "\n",
    "from pandas import Series\n",
    "from pandas import DataFrame\n",
    "from typing import List,Tuple\n",
    "\n",
    "from pandas import Categorical\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "from tqdm import tnrange#, tqdm_notebook\n",
    "from plotnine import *\n",
    "\n",
    "# Local imports\n",
    "from common import *\n",
    "from convenience import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I.  Normal distribution as a resulting probability assignment \n",
    "\n",
    "The Hammersley-Clifford theorem gives a lot of freedom how one can specify the full distribution $p[\\boldsymbol{x}|\\omega]$. \n",
    "In principle, we could search for optimal potential functions $\\Psi_c$ by estimating \n",
    "\n",
    "\\begin{align*}\n",
    "\\Pr[x_i|(x_j)_{j\\in\\mathsf{Neighbours}(X_i)}]\n",
    "\\end{align*}\n",
    "\n",
    "for all pixels $x_i$ and then fix discrete sub-potentials $\\Psi_c$ that lead to the estimated conditional probabilities. \n",
    "However, the amount of data needed to get reliable estimates for sub-potentials is immense. \n",
    "Hence, the classical approach is to severely restrict the shape of sub-potentials.\n",
    "\n",
    "\n",
    "If we define all individual potentials $\\Psi_c$ as quadratic forms over $\\boldsymbol{x}_c$, the resulting distribution $p[\\boldsymbol{x}|\\omega]$ will be a multivariate normal distribution. \n",
    "The latter allows us to obtain analytical solutions for basic inference tasks that are generally doable with complex MCMC simulation algorithms.\n",
    "The main aim of this tutorial is to demonstrate the remarkable properties of multivariate normal distribution that provide necessary formulae to get the analytical solution.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Four-dimensional multivariate normal distribution as a solution to 2 x 2 MRF \n",
    "\n",
    "The $2\\times 2$ Markov random field has four edges that are also maximal cliques: $(X_1, X_2)$, $(X_2,X_3)$, $(X_3, X_4)$ and $(X_4, X_1)$.\n",
    "\n",
    "<img src = 'illustrations/markov-random-field-iv.png' width=100%>\n",
    "\n",
    "Let us consider the subpotential $\\Psi_1$ corresponding to the first edge $(X_1,X_2)$. If we restrict $\\Psi_1(x_1,x_2)$ to quadratic forms then the search space is\n",
    "\n",
    "\\begin{align*}\n",
    "\\Psi_1(x_1,x_2)= a_{11} x_1^2+2a_{12}x_1x_2+ a_{22}x_2^2\\enspace\n",
    "\\end{align*}\n",
    "for $a_{11},a_{12},a_{22}\\in\\mathbb{R}$. \n",
    "In most applications, we would like that $x_1\\approx x_2$ and thus we can restrict the search space even more \n",
    "\n",
    "\\begin{align*}\n",
    "\\Psi_1(x_1,x_2)= \\alpha(x_{1}-x_2)^2=\\alpha x_1^2-2\\alpha x_1x_2+\\alpha x_2^2\\enspace\n",
    "\\end{align*}\n",
    "\n",
    "for $\\alpha\\in\\mathbb{R}^+$.\n",
    "Analogous reasoning for the other edges leads to the following subpotentials\n",
    "\n",
    "\\begin{align*}\n",
    "\\Psi_1(x_1,x_2)&= \\alpha_1(x_{1}-x_2)^2=\\alpha_1 x_1^2-2\\alpha_1 x_1x_2+\\alpha_1 x_2^2\\\\\n",
    "\\Psi_2(x_2,x_3)&= \\alpha_2(x_{2}-x_3)^2=\\alpha_2 x_2^2-2\\alpha_2 x_2x_3+\\alpha_2 x_3^2\\\\\n",
    "\\Psi_3(x_3,x_4)&= \\alpha_3(x_{3}-x_4)^2=\\alpha_3 x_3^2-2\\alpha_3 x_3x_4+\\alpha_3 x_4^2\\\\\n",
    "\\Psi_4(x_4,x_1)&= \\alpha_4(x_{4}-x_1)^2=\\alpha_4 x_4^2-2\\alpha_4 x_4x_1+\\alpha_4 x_1^2\\\\\n",
    "\\end{align*}\n",
    "\n",
    "and thus the probability of the entire MRF is\n",
    "\n",
    "\\begin{align*}\n",
    "p[x_1,x_2,x_3,x_4|\\alpha_1,\\alpha_2,\\alpha_3,\\alpha_4]&=\n",
    "\\frac{1}{Z(\\alpha_1,\\alpha_2,\\alpha_3,\\alpha_4)}\\cdot\\exp\\bigl(-\\Psi(x_1,x_2,x_3,x_4)\\bigr)\\\\\n",
    "\\end{align*}\n",
    "\n",
    "where\n",
    "\n",
    "\\begin{align*}\n",
    "\\Psi(x_1,x_2,x_3,x_4)=\n",
    "(\\alpha_1+\\alpha_4) x_1^2+\n",
    "(\\alpha_1+\\alpha_2) x_2^2+\n",
    "(\\alpha_2+\\alpha_3) x_3^2+\n",
    "(\\alpha_3+\\alpha_4) x_4^2\n",
    "-2\\alpha_1 x_1x_2\n",
    "-2\\alpha_2 x_2x_3\n",
    "-2\\alpha_3 x_3x_4\n",
    "-2\\alpha_4 x_4x_1\\enspace.\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "If we write the potential energy $\\Psi(\\boldsymbol{x})$ using matrix operations we get\n",
    "\n",
    "\\begin{align*}\n",
    "\\Psi(\\mathbf{x})=\n",
    "\\mathbf{x}^T\n",
    "\\begin{pmatrix}\n",
    "\\alpha_1+\\alpha_4 & -\\alpha_1 & 0 & -\\alpha_4\\\\\n",
    "-\\alpha_1 &\\alpha_1+\\alpha_2 & -\\alpha_2 & 0 \\\\\n",
    "0 &-\\alpha_2 &\\alpha_2+\\alpha_3 & -\\alpha_3 \\\\\n",
    "-\\alpha_4 & 0 &-\\alpha_3 &\\alpha_3+\\alpha_4 \\\\\n",
    "\\end{pmatrix}\n",
    "\\mathbf{x} = \\mathbf{x}^T A\\mathbf{x} \n",
    "\\end{align*}\n",
    "for a coefficient matrix $A$.\n",
    "As a four-dimensional multivariate normal distribution has density \n",
    "\n",
    "\\begin{align*}\n",
    "p(\\boldsymbol{x}|\\boldsymbol{\\mu},\\boldsymbol{\\Sigma})\\propto \\exp\\Biggl(-\\frac{1}{2}\\cdot(\\boldsymbol{x}-\\boldsymbol{\\mu})^T\\boldsymbol{\\Sigma}^{-1} (\\boldsymbol{x}-\\boldsymbol{\\mu})\\Biggl)\\enspace,\n",
    "\\end{align*}\n",
    "\n",
    "we get that our probability assignment indeed corresponds to a multivariate normal distribution with parameters $\\boldsymbol{\\mu}=\\boldsymbol{0}$ and $\\boldsymbol{\\Sigma}^{-1}=2\\cdot A$.\n",
    "Analogous derivation and shape matching with multivariate normal distribution can be done for any Markov random field. That is, based on some intuition we directly fix the inverse covariance matrix of the multivariate normal distribution and then determine the scaling factor $Z(\\omega)$ directly from the density formula.      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Linear regression model for smallest neighbourhood\n",
    "\n",
    "Let us consider the the four pixel neighbourhood of a particular pixel\n",
    "<img src = 'illustrations/markov-random-field-v.png' width=30%>\n",
    "\n",
    "The linear model formulation implies \n",
    "\n",
    "\\begin{align*}\n",
    "y=\\beta_1x_1+\\beta_2x_2+ \\beta_3x_3+\\beta_4x_4+\\beta_0+\\varepsilon,\n",
    "\\qquad \\varepsilon\\sim\\mathcal{N}(0,\\sigma)\n",
    "\\end{align*}\n",
    "\n",
    "The Hammersley-Clifford theorem gives \n",
    "\n",
    "\\begin{align}\n",
    "p[x_1,x_2,x_3,x_4, y]\\propto\\mathrm{exp}\\left(-\\psi(x_1,y)-\\psi_2(x_2,y)-\\psi_3(x_3,y)-\\psi_4(x_4, y)\\right)\n",
    "\\end{align}\n",
    "\n",
    "from which we can conclude \n",
    "\n",
    "\\begin{align*}\n",
    " p[y|x_1,x_2,x_3,x_4,]&=\\frac{p[y,x_1,x_2,x_3,x_4]}{p[x_1,x_2,x_3,x_4]}\n",
    " \\propto p[y,x_1,x_2,x_3,x_4]\n",
    "\\end{align*}\n",
    "Consequently we can espress\n",
    "\n",
    "\\begin{align*}\n",
    " p[y|x_1,x_2,x_3,x_4,]&\\propto \\mathrm{exp}\\left(-\\psi(x_1,y)-\\psi_2(x_2,y)-\\psi_3(x_3,y)-\\psi_4(x_4, y)\\right)\n",
    "\\end{align*}\n",
    "\n",
    "The probabilistic model on the other hand gives\n",
    "\n",
    "\\begin{align}\n",
    " p[y|x_1,x_2,x_3,x_4,]&\\propto \\mathrm{exp}\\left(-\\frac{(y-\\beta_1x_1-\\beta_2x_2- \\beta_3x_3-\\beta_4x_4-\\beta_0)^2}{2\\sigma^2}\\right)\\\\\n",
    " &\\propto\\mathrm{exp}\\left(-\\frac{y^2-2\\beta_1x_1 y-2\\beta_2x_2y- \\beta_3x_3y-2\\beta_4x_4y-2\\beta_0y}{2\\sigma^2}\\right)\\\\\n",
    " &\\propto\\mathrm{exp}\\left(-\\frac{(y-4\\beta_1x_1)^2 -(y-4\\beta_2x_2)^2- (y-4\\beta_3x_3)^2-(y-4\\beta_4x_4)^2-8\\beta_0y}{8\\sigma^2}\\right)\\\\\n",
    " &\\propto\\mathrm{exp}\\left(-\\frac{(y-4\\beta_1x_1-\\beta_0)^2 -(y-2\\beta_2x_2-\\beta_0)^2- (y-\\beta_3x_3-\\beta_0)^2-(y-2\\beta_4x_4-\\beta_0)^2}{8\\sigma^2}\\right)\\\\ \n",
    "\\end{align}\n",
    "\n",
    "As a result, we obtain the desired correspondence\n",
    "\n",
    "\\begin{align*}\n",
    "\\psi_1(x_1,y)&=\\frac{(y-4\\beta_1x_1-\\beta_0)^2}{8\\sigma^2}\\\\\n",
    "\\psi_2(x_2,y)&=\\frac{(y-4\\beta_2x_2-\\beta_0)^2}{8\\sigma^2}\\\\\n",
    "\\psi_3(x_3,y)&=\\frac{(y-4\\beta_3x_3-\\beta_0)^2}{8\\sigma^2}\\\\\n",
    "\\psi_4(x_4,y)&=\\frac{(y-4\\beta_4x_4-\\beta_0)^2}{8\\sigma^2}\n",
    "\\end{align*}\n",
    "\n",
    "Thus we can estimate the sub-potentials through the linear regression model given enough samples of independent patches from the image.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home exercises\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Correspondence with homogenous MRF for 3 x 3 grid* (<font color='red'>4p</font>)\n",
    "\n",
    "\n",
    "The simplest homogenous MRF model each node is influenced by four of its closest neighbours where \n",
    "\n",
    "* the deviations from the mean pixel intensity are penalised by $\\frac{1}{2}\\cdot\\delta^2 x_{ij}$\n",
    "* the differeces in the horisontal direction are penalised by $\\frac{1}{2}\\cdot\\alpha (x_{ij}-x_{i,j+1})^2$\n",
    "* the differeces in the vertical direction are penalised by $\\frac{1}{2}\\cdot\\beta (x_{ij}-x_{i+1,j})^2$\n",
    "\n",
    "Express the density function for $p[x_0,x_1, \\ldots, x_8]$ up to a multiplicative constant for $3\\times 3$ grid depicted below \n",
    "<img src = 'illustrations/markov-random-field-ii.png' width=100%>\n",
    "\n",
    "Again express the conditional probability $p[x_4|x_0,\\ldots,x_8]$ up to a multiplicative constant from the linear regression formulation. \n",
    "This will lead to constraints on the linear regrssion formulation. \n",
    "* Define the corresponding linear regression task (<font color='red'>1p</font>).\n",
    "* Solve it for non-overlapping moss textures (<font color='red'>1p</font>).\n",
    "* Solve the direct maximum likelihood estimation for  moss textures (<font color='red'>1p</font>).\n",
    "* Show that the results are equal (<font color='red'>1p</font>)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Correspondence with homogenous MRF for n x n grid* (<font color='red'>5p</font>)\n",
    "\n",
    "Find a maximum likelihod solution for parameters $\\alpha, \\beta, \\delta$ for a general $n\\times n$ grid. The main issue is that the normalizing factor $Z(\\alpha, \\beta, \\delta)$ depends on the variables we want to fit and thus cannot be treated as a constant. Nevertheless, you can still estimate $x_{ij}$ through a linear model using neighbouring points. Since a point can be located in both ends of the edge you get different formalisations. Find a heuristic solution to consolidate tasks.   \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
