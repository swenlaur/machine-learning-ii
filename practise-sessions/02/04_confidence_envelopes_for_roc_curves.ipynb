{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confidence envelopes for ROC curves\n",
    "\n",
    "A ROC curve $\\mathrm{Roc}:[0,1]\\to[0,1]$ packs a lot of information about a classifer. \n",
    "In particular, it allows to choose good trade-off points between recall and precision, or compare the performance of different classifiers.\n",
    "Note that we cannot compute the true ROC curve as it is determined by the exact data distributions of positive and negative classes.\n",
    "Instead we can only compute the approximation on a test set and thus the graph is bound to fluctuate.\n",
    "By computing the confidence envelopes, we could characterise the uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import numpy.random as rnd\n",
    "\n",
    "from pandas import Series\n",
    "from pandas import DataFrame\n",
    "\n",
    "from tqdm import tnrange\n",
    "from plotnine import *\n",
    "\n",
    "# Local imports\n",
    "from common import *\n",
    "from convenience import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Theoretical model behind the ROC curve\n",
    "\n",
    "First note that the ideal ROC curve is given by the following parametric equation\n",
    "\n",
    "\\begin{align*}\n",
    "\\begin{cases}\n",
    "\\alpha(\\tau) = \\Pr[\\boldsymbol{x}\\gets\\mathcal{D}_{-}: f(\\boldsymbol{x})\\geq \\tau]\\\\\n",
    "\\beta(\\tau) = \\Pr[\\boldsymbol{x}\\gets\\mathcal{D}_{+}: f(\\boldsymbol{x})\\geq \\tau]\\enspace,\n",
    "\\end{cases}\n",
    "\\end{align*}\n",
    "\n",
    "where \n",
    "* $\\mathcal{D}_{+}$ and $\\mathcal{D}_{-}$ are the data distributions of positive and negative cases, respectively\n",
    "* $f(\\boldsymbol{x})$ is the decision value assigned to data point $\\boldsymbol{x}$\n",
    "* $\\tau$ is the threshold above which all decision values are declared as positive\n",
    "\n",
    "From this definition it is easy to see that $\\alpha(\\tau)$ is the ratio of false positives and $\\beta(\\tau)$ is the ratio of true positives in a setting where the number of test samples is infinite. \n",
    "\n",
    "In practice we observe $N$ negative samples and $P$ positive samples in the test set. If all the test samples are iid then  \n",
    "* all the negative samples are iid samples from $\\mathcal{D}_{-}$\n",
    "* all the positive samples are iid samples from $\\mathcal{D}_{+}$\n",
    "\n",
    "Thus the number of false positives $\\mathrm{FP}$ and true positives $\\mathrm{TP}$ are distributed according to binomial distributions: \n",
    "\n",
    "\\begin{align*}\n",
    "\\mathrm{FP}&\\sim\\mathrm{Bin}(n=N, p=\\alpha(\\tau))\\\\\n",
    "\\mathrm{TP}&\\sim\\mathrm{Bin}(n=P, p=\\beta(\\tau))\n",
    "\\end{align*}\n",
    "\n",
    "As the number of true and false positives are independent if the number of negative and positive cases are fixed, it is straightforward to assign a probability to the pair $(\\mathrm{FP},\\mathrm{TP})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. How to define a statistical test for the pair of ratios\n",
    "\n",
    "In order to get further, we must define a single test statistic for which we can compute the probability. This will determine how narrow will be the confidence envelope for the ROC curve, hence we must be careful. There are three natural ways to define the test statistic.\n",
    "\n",
    "### The acceptance region will be a square box\n",
    "\n",
    "Given parameters $N$, $P$, $\\alpha$, $\\beta$, we can easily compute the probability assigned to the square box centered around the expected values of $FP$ and $TP$:  \n",
    "\n",
    "\\begin{align*}\n",
    "f(\\Delta_1,\\Delta_2)= \\Pr[|FP-N\\alpha|\\leq \\Delta_1\\wedge |TP-P\\beta|\\leq \\Delta_2]\n",
    "\\end{align*}\n",
    "\n",
    "Minimising $\\Delta_1$ and $\\Delta_2$ such that $f(\\Delta_1,\\Delta_2)\\geq 1-\\rho$, where $\\rho$ is the desired significance level, will give us a statistical test.\n",
    "\n",
    "\n",
    "### The acceptance region will be the cells with maximal probability\n",
    "\n",
    "As we can compute the probability for any $(FP, TP)$ pair, we can order them and reject the tail with weight $\\rho$. This will be a slightly more powerful test as we accept the region of the highest probability mass, i.e., the points that are typical to the distribution.\n",
    "\n",
    "\n",
    "### Acceptance region will be an ellips determined by a normal approximation\n",
    "\n",
    "Note that for moderately large values of $N$ and $P$, the binomial distribution converges to a normal distribution. \n",
    "As $FP$ and $NP$ are independent, we can approximate $(FP,TP)$ by a normal distribution where only the diagonals contain non-zero entries. By proper scaling, we can make sure that $(\\gamma_1\\cdot FP,\\gamma_2\\cdot TP)$ can be approximated with white Gaussian noise $\\mathcal{N}(0, I)$. For that distribution the best test statistic is distance squared\n",
    "$\\gamma_1^2\\cdot FP^2 +\\gamma_2^2\\cdot TP^2$, which is distributed according to a $\\chi^2$-distribution with two degrees of freedom. This gives rise to another test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Compare tests for the pair of ratios* (<font color='red'>3p</font>)  \n",
    "\n",
    "Implement all of the three tests and compare their acceptance regions for the case $N=P$ and $N\\in\\{10, 50, 100, 1000\\}$.\n",
    "Compare the power of these tests by considering the hypotheses $(\\alpha,\\beta)$ and $(\\alpha+\\delta, \\beta+\\delta)$:\n",
    "* for some reasonable $\\delta$ values in the range $[0, 0.1]$\n",
    "* for some reasonable $\\alpha, \\beta$ values in the box $[0,1]\\times[0,1]$\n",
    "\n",
    "Can you decide which test is the best to use in computing confidence intervals for comparing hypotheses $(\\alpha,\\beta)$ and $(\\alpha+\\delta_1, \\beta+\\delta_2)$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Build  a confidence envelope for the ROC curve* (<font color='red'>3p</font>)  \n",
    "\n",
    "Use the naive grid testing approach to build a confidence envelope:\n",
    "* For each $(FP,TP)$ pair in the empirical ROC curve compute the acceptance region for $(\\alpha_i,\\beta_i)$.\n",
    "* Merge all the acceptance regions and compute convex hull around it.\n",
    "* Declare the result as the confidence envelope.\n",
    "\n",
    "Test whether the construction gives indeed a pointwise confidence envelope. For each $(FP,TP)$ pair the corresponding estimate $FP/N,TP/P$ is guaranteed to be in the envelope with confidence at least $1-\\rho$ by construction, but if individual regions overlap the confidence can be much larger. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
