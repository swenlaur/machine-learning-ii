{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test statistic and p-value assignment\n",
    "\n",
    "Recall that any non-adaptive classification algorithm that does not use training set to tune its parameters can be converted to a statistical test. For that we must fix a null hypothesis as a source of negative samples and measure the false positives rate.\n",
    "Usually, a classifier internally computes a decsision value $t$ aka test score and different trade-offs are possible.\n",
    "Thus we can assign false positive rate $p(t)$ for each theshold value $t$. \n",
    "This value is known as p-value.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import numpy.random as rnd\n",
    "\n",
    "from pandas import Series\n",
    "from pandas import DataFrame\n",
    "\n",
    "from tqdm import tnrange\n",
    "from plotnine import *\n",
    "\n",
    "# Local imports\n",
    "from common import *\n",
    "from convenience import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Formal definition of a p-value\n",
    "\n",
    "Let $t$ be a test statistic computed from a sample $\\boldsymbol{x}$ as $f(\\boldsymbol{x})$. Let $\\mathcal{D}$ be the distribution of $\\boldsymbol{x}$ determined by the null hypotesis. Then p-value is a probability\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathrm{pvalue}(t)=\\Pr[\\boldsymbol{x}_*\\gets\\mathcal{B}, t_*=f(\\boldsymbol{x}_*): t_*\\geq t]\\enspace.\n",
    "\\end{align*}\n",
    "\n",
    "Note that this definition corresponds to a classifier that classifier all samples $\\boldsymbol{x}$ as negatives if $f(\\boldsymbol{x})\\geq t$ and $\\mathrm{pvalue}(t)$ is just the fraction of false positives.\n",
    "\n",
    "Obviously, we can reverse the classification rule and then  p-value is a probability\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathrm{pvalue}(t)=\\Pr[\\boldsymbol{x}_*\\gets\\mathcal{B}, t_*=f(\\boldsymbol{x}_*): t_*\\leq t]\\enspace.\n",
    "\\end{align*}\n",
    "\n",
    "Both definitions are quite common. Intuitively, you should fix the direction based extremeness. \n",
    "If you consider larger values more extreme then you should consider the first formula. It is also possible to use double treshold and consider cut-off based $|t|$. This leads to the third formula\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathrm{pvalue}(t)=\\Pr[\\boldsymbol{x}_*\\gets\\mathcal{B}, t_*=f(\\boldsymbol{x}_*): |t_*|\\geq |t|]\\enspace.\n",
    "\\end{align*}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical power of a test\n",
    "\n",
    "Different classification algorithms are good for different task. The same is true for statistical tests.\n",
    "Thresholding bases on p-value allows us to control the ratio of false positives (significance level).\n",
    "On the same time it also affects the ratio of false negatives. The latter is harder to quantify as it depends on two factors:\n",
    "* definition of a test statistic (*statistical test*)\n",
    "* the data distribution of positive cases (*alternative hypothesis*)\n",
    "\n",
    "Of course, a test cannot really work equally good for all alternative hypotheses.\n",
    "Hence, a statistical test is commonly defined to work well for all reasonable alternative hypotheses.\n",
    "For instance, let the null hypothesi be that the iid data sample is form a normal distibution $\\mathcal{N}(\\mu=0,\\sigma=1)$. Then it makes sense to consider a class of alternative hypotheses where the iid data sample is from a normal distribution $\\mathcal{N}(\\mu\\neq 0,\\sigma=1)$. \n",
    "This situation naturally arrises in quality control were we must check that some physical quantity is zero and the measurement procedure is corrupted by additive Gaussian noise $\\mathcal{N}(\\mu=0,\\sigma=1)$. \n",
    "\n",
    "Now for any alternative hypothesis spacified by distibution $\\mathcal{D}$ we can compute the recall probability\n",
    "\n",
    "\\begin{align*}\n",
    "\\Pr[data\\gets \\mathcal{D}: \\text{test accepts }]\\enspace.\n",
    "\\end{align*}\n",
    "\n",
    "This is known as **power** of the statistical test. A good test has large recall for alternative hypotheses. \n",
    "For our example case, the latter cannot be achieved since $\\mathcal{N}(\\mu=0,\\sigma=1)$ can be arbitrarily close to \n",
    "$\\mathcal{N}(\\mu=0,\\sigma=1)$. In general, the best we can achive is that for all alternaive hypotheses our test performs roughly as well as the best test designed for that null hypothesis and alternative hypothesis pair. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Properties of p-value (<font color='red'>1p</font>)\n",
    "\n",
    "Let the test statistic $t$ be $t=\\sin(x)$. Find p-value function $\\mathrm{pvalue}(t)$ for the null hypothesis where $x$ is sampled uniformly form the range $[-\\pi, \\pi]$. Find out what is the distribution of $\\mathrm{pvalue}(t)$ for $t=\\sin(x)$. Explain why do you get this result?\n",
    "* You can use simulation or simple probability computations to determine when $\\sin(x_*)\\geq t$.\n",
    "* You can use simulation or simple probability computations to determine the disttibution of $\\mathrm{pvalue}(t)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Power of a statistical test (<font color='red'>1p</font>)\n",
    "\n",
    "Consider two statistical tests defined by the test statistics $t_1=\\sin(x)$ and $t_2=\\cos(x)$. Find p-value function $\\mathrm{pvalue}_i(t)$ for the null hypothesis where $x$ is sampled form $\\mathcal{N}(\\mu=0, \\sigma=1)$.\n",
    "As an alternative hypothesis consider the case that $x$ is samples from $\\mathcal{N}(\\mu\\neq 0, \\sigma=1)$.\n",
    "For simplicity you can fix $\\mu=1$.\n",
    "Compute the power of both tests for the significance level $5\\%$.\n",
    "You can do simulations but there exists a simple closed form solution for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
