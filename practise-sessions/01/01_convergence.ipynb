{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convergence of training and test error\n",
    "\n",
    "According to statistical learning theory, training and test errors converge when the number of training samples grows for all **reasonable machine learning methods**. However, the convergence speeds really depends on many factors. The following notebook highlights the differences and causes behind them.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as random\n",
    "import pandas as pd\n",
    "\n",
    "from pandas import Series\n",
    "from pandas import DataFrame\n",
    "from typing import List\n",
    "\n",
    "# Local imports\n",
    "from common import *\n",
    "from convenience import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Data generation functions \n",
    "\n",
    "Code for generating data according to logistic regression model:\n",
    "\n",
    "* The binary data matrix X is generated randomly.\n",
    "* The target vector y is generated according to logit model.\n",
    "\n",
    "We generate two types of data matrices:\n",
    "\n",
    "* compact matrices where all features are needed for prediction\n",
    "* matrices with extra columns that do not contain any information for prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random functions** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "def logit(x:Series, w:Series):\n",
    "    \"\"\"\n",
    "    Labels output according to logit model pr[y=1|sigmoid(w*x)]\n",
    "    \n",
    "    You can omit trailing zeroes in w by specifying only first non-zero coefficients  \n",
    "    \"\"\"\n",
    "    return random.rand() <= sigmoid(np.dot(x.iloc[0:len(w)] - 0.5, w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_sampler(n:int, k:int,  f:callable) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Data generator that generates n x k feature matrix and a target vector\n",
    "    \n",
    "    Returns a data frame with columns x_1, ..., x_k, y where y is computed\n",
    "    using randomised labelling function f.\n",
    "    \"\"\"\n",
    "    \n",
    "    columns = ['x_{}'.format(num) for num in range(1, k + 1)]\n",
    "    return (DataFrame(random.rand(n, k), columns = columns)\n",
    "            .transform(lambda x: x >= 0.5)\n",
    "            .assign(y = lambda df: df.apply(f, axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Example datasets\n",
    "\n",
    "* The size of the dataset and nature of the labelling function determine the difficulty of the problem.\n",
    "* If the target function is near-deterministic then there exists a good predictor.\n",
    "* If the number of features is small then it is easier to learn the target function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Choosing among target functions\n",
    "\n",
    "* Let's build a target function that outputs `True` if at least one input is `True`.\n",
    "* The weights `w = [1, 1]` achieve this most of the time (the relation is not absolute).\n",
    "* Larger weights `[10, 10]` increase certainty and smaller weights `[0.1, 0.1]` decrease certainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     x_1    x_2      y\n",
       "0  False   True  False\n",
       "1   True  False   True\n",
       "2  False   True  False\n",
       "3   True   True  False\n",
       "4   True   True   True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs = lambda x: logit(x, Series([1, 1]))\n",
    "X = data_sampler(1000, 2, fs)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let see what is the fraction of `True` values for each input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>count</th>\n",
       "      <th>sum</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>234</td>\n",
       "      <td>63.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>258</td>\n",
       "      <td>136.0</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>243</td>\n",
       "      <td>129.0</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>265</td>\n",
       "      <td>183.0</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     x_1    x_2  count    sum  freq\n",
       "0  False  False    234   63.0  27.0\n",
       "1  False   True    258  136.0  53.0\n",
       "2   True  False    243  129.0  53.0\n",
       "3   True   True    265  183.0  69.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S = X.groupby(['x_1', 'x_2']).aggregate(['count', 'sum'])\n",
    "S.columns = S.columns.droplevel(0)  \n",
    "S = S.assign(freq = lambda df: round(df['sum']/df['count'] * 100))\n",
    "S.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The relation between inputs and output is not so clear:\n",
    "* Let's experiment with different weights to see what happens.\n",
    "* For simplicity, let's convert the previous analysis to a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>count</th>\n",
       "      <th>sum</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>234</td>\n",
       "      <td>63.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>258</td>\n",
       "      <td>136.0</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>243</td>\n",
       "      <td>129.0</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>265</td>\n",
       "      <td>183.0</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     x_1    x_2  count    sum  freq\n",
       "0  False  False    234   63.0  27.0\n",
       "1  False   True    258  136.0  53.0\n",
       "2   True  False    243  129.0  53.0\n",
       "3   True   True    265  183.0  69.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def summarize(X:DataFrame) -> DataFrame:\n",
    "    S = X.groupby(['x_1', 'x_2']).aggregate(['count', 'sum'])\n",
    "    S.columns = S.columns.droplevel(0)  \n",
    "    return (S.assign(freq = lambda df: round(df['sum']/df['count'] * 100)).\n",
    "            reset_index())  \n",
    "display(summarize(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To estimate the effect of statistical fluctuations we do two experiments and compare results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"display:inline\"><tr><td style=\"text-align:center\">Sample 1</td><td style=\"text-align:center\">Sample 2</td></tr><tr><td style=\"vertical-align:top\"> <table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>x_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>count</th>\n",
       "      <th>sum</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>260</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>250</td>\n",
       "      <td>126.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>254</td>\n",
       "      <td>115.0</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>236</td>\n",
       "      <td>236.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\"></td><td style=\"vertical-align:top\"> <table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>x_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>count</th>\n",
       "      <th>sum</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>232</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>257</td>\n",
       "      <td>129.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>235</td>\n",
       "      <td>128.0</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>276</td>\n",
       "      <td>276.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\"></td></tr></table style=\"display:inline\">"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table style=\"display:inline\"><tr><td style=\"text-align:center\">Sample 1</td><td style=\"text-align:center\">Sample 2</td></tr><tr><td style=\"vertical-align:top\"> <table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>x_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>count</th>\n",
       "      <th>sum</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>269</td>\n",
       "      <td>133.0</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>223</td>\n",
       "      <td>115.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>267</td>\n",
       "      <td>120.0</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>241</td>\n",
       "      <td>137.0</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\"></td><td style=\"vertical-align:top\"> <table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>x_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>count</th>\n",
       "      <th>sum</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>250</td>\n",
       "      <td>126.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>283</td>\n",
       "      <td>133.0</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>223</td>\n",
       "      <td>113.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>244</td>\n",
       "      <td>130.0</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\"></td></tr></table style=\"display:inline\">"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = data_sampler(1000, 2, lambda x: logit(x, Series([10, 10])))\n",
    "S1 = summarize(X)\n",
    "X = data_sampler(1000, 2, lambda x: logit(x, Series([10, 10])))\n",
    "S2 = summarize(X)\n",
    "mdisplay([S1, S2], ['Sample 1', 'Sample 2'])\n",
    "\n",
    "X = data_sampler(1000, 2, lambda x: logit(x, Series([0.1, 0.1])))\n",
    "S1 = summarize(X)\n",
    "X = data_sampler(1000, 2, lambda x: logit(x, Series([0.1, 0.1])))\n",
    "S2 = summarize(X)\n",
    "mdisplay([S1, S2], ['Sample 1', 'Sample 2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:** The number of samples is too small to get an accurate probability estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"display:inline\"><tr><td style=\"text-align:center\">Sample 1</td><td style=\"text-align:center\">Sample 2</td></tr><tr><td style=\"vertical-align:top\"> <table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>x_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>count</th>\n",
       "      <th>sum</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>24875</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>25192</td>\n",
       "      <td>12656.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>25030</td>\n",
       "      <td>12599.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>24903</td>\n",
       "      <td>24901.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\"></td><td style=\"vertical-align:top\"> <table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>x_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>count</th>\n",
       "      <th>sum</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>25051</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>25146</td>\n",
       "      <td>12567.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>25057</td>\n",
       "      <td>12563.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>24746</td>\n",
       "      <td>24743.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\"></td></tr></table style=\"display:inline\">"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table style=\"display:inline\"><tr><td style=\"text-align:center\">Sample 1</td><td style=\"text-align:center\">Sample 2</td></tr><tr><td style=\"vertical-align:top\"> <table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>x_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>count</th>\n",
       "      <th>sum</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>24739</td>\n",
       "      <td>11710.0</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>24894</td>\n",
       "      <td>12606.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>25124</td>\n",
       "      <td>12517.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>25243</td>\n",
       "      <td>13258.0</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\"></td><td style=\"vertical-align:top\"> <table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>x_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>count</th>\n",
       "      <th>sum</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>24869</td>\n",
       "      <td>11925.0</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>25020</td>\n",
       "      <td>12454.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>25207</td>\n",
       "      <td>12486.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>24904</td>\n",
       "      <td>12998.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\"></td></tr></table style=\"display:inline\">"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = data_sampler(100000, 2, lambda x: logit(x, Series([10, 10])))\n",
    "S1 = summarize(X)\n",
    "X = data_sampler(100000, 2, lambda x: logit(x, Series([10, 10])))\n",
    "S2 = summarize(X)\n",
    "mdisplay([S1, S2], ['Sample 1', 'Sample 2'])\n",
    "\n",
    "X = data_sampler(100000, 2, lambda x: logit(x, Series([0.1, 0.1])))\n",
    "S1 = summarize(X)\n",
    "X = data_sampler(100000, 2, lambda x: logit(x, Series([0.1, 0.1])))\n",
    "S2 = summarize(X)\n",
    "mdisplay([S1, S2], ['Sample 1', 'Sample 2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Weight vector `w = [10, 10]` creates predictable instances.\n",
    "* Weight vector `w = [0.1, 0.1]` creates almost unpredictable instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing learning tasks to compare\n",
    "\n",
    "* Let's experiment with predictable and almost unpredictable labelling functions.\n",
    "* Let's experiment with small and big number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler_11 = lambda n: data_sampler(n, 2, lambda x: logit(x, Series([10, 10])))\n",
    "sampler_10 = lambda n: data_sampler(n, 2, lambda x: logit(x, Series([0.1, 0.1])))\n",
    "sampler_01 = lambda n: data_sampler(n, 15, lambda x: logit(x, Series([10, 10])))\n",
    "sampler_00 = lambda n: data_sampler(n, 15, lambda x: logit(x, Series([0.1, 0.1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Learning algorithms\n",
    "\n",
    "* Let's observe the behaviour of several algorithms.\n",
    "* Majority voting is the simplest and the best classification algorithm:\n",
    "  * It is optimal if the number of samples is large enough to cover each possible input.\n",
    "  * It is theoretically optimal â€“ we cannot do better without extra knowledge about the data.\n",
    "* Logistic regression can work with fewer samples:\n",
    "  * It makes extra assumptions about the labelling function.\n",
    "  * As a result, there are fewer parameters to learn.\n",
    "  * The convergence to the final classification algorithm is faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Majority voting algorithm\n",
    "\n",
    "* Our implementation corresponds to `sklearn` prediction API:\n",
    "  * constructor for fixing free hyperparameters\n",
    "  * method `fit(samples, targets)` to train the model\n",
    "  * method `predict(samples)` to predict labels\n",
    "  * method `set_params(...)` to set hyperparameters  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MajorityVoting:\n",
    "    \n",
    "    def __init__(self, features:List[str]=None):\n",
    "        if features:\n",
    "            self.features = list(features)\n",
    "        else:\n",
    "            self.features = None\n",
    "    \n",
    "    def set_params(features: List[str]) -> None:\n",
    "        self.features = features\n",
    "    \n",
    "    def fit(self, X: DataFrame, y: Series) -> None:\n",
    "        \n",
    "        if self.features is None:\n",
    "            self.features = list(X.columns.values)\n",
    "\n",
    "        data = X.assign(y = y)\n",
    "        pred = data.groupby(self.features).aggregate(['count', 'sum'])\n",
    "        pred.columns = pred.columns.droplevel(0)\n",
    "        self.pred = DataFrame({'prediction':(pred['sum']/pred['count'] >= 0.5)})\n",
    "    \n",
    "    def predict(self, X: DataFrame) -> np.array:\n",
    "        \n",
    "        return (X[self.features]\n",
    "                .join(self.pred, on=self.features, how='left')['prediction']\n",
    "                .fillna(True)\n",
    "                .values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Majority voting:** example run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"display:inline\"><tr><td style=\"text-align:center\">Data</td><td style=\"text-align:center\">Predictor</td></tr><tr><td style=\"vertical-align:top\"> <table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>x_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\"></td><td style=\"vertical-align:top\"> <table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\"></td></tr></table style=\"display:inline\">"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf = MajorityVoting()\n",
    "data = sampler_11(2)\n",
    "features = list(data.columns.values)[0:-1]\n",
    "clf.fit(data[features], data['y'])\n",
    "mdisplay([data, clf.pred],['Data', 'Predictor'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic regression:** example run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: True",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-eddea2790c14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'lbfgs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/machine-learning/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1556\u001b[0m             raise ValueError(\"This solver needs samples of at least 2 classes\"\n\u001b[1;32m   1557\u001b[0m                              \u001b[0;34m\" in the data, but the data contains only one\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1558\u001b[0;31m                              \" class: %r\" % classes_[0])\n\u001b[0m\u001b[1;32m   1559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1560\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: True"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "data = sampler_11(2)\n",
    "\n",
    "clf = LogisticRegression(solver = 'lbfgs')\n",
    "features = list(data.columns.values)[0:-1]\n",
    "clf.fit(data[features], data['y'])\n",
    "clf.predict(data[features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV.  Convergence plots for accuracy\n",
    "\n",
    "* We generate different datasets of different sizes and estimate classifiers' performance on the test set.\n",
    "* To eliminate fluctuations based on test data generation, we use the same testset for all training set sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation of training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = [10, 50, 100] + list(range(200, 1001, 100)) + list(range(2000, 5001, 1000))\n",
    "\n",
    "train_00 = [sampler_00(n) for n in sizes]\n",
    "features_00 = list(train_00[0].columns.values[0:-1])\n",
    "\n",
    "train_01 = [sampler_01(n) for n in sizes]\n",
    "features_01 = list(train_01[0].columns.values[0:-1])\n",
    "\n",
    "train_10 = [sampler_10(n) for n in sizes]\n",
    "features_10 = list(train_10[0].columns.values[0:-1])\n",
    "\n",
    "train_11 = [sampler_11(n) for n in sizes]\n",
    "features_11 = list(train_11[0].columns.values[0:-1])\n",
    "\n",
    "n = 10000\n",
    "test_00 = sampler_00(n)\n",
    "test_01 = sampler_01(n)\n",
    "test_10 = sampler_10(n)\n",
    "test_11 = sampler_11(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Majority Voting example  \n",
    "\n",
    "To work out the details, it is always easier to do the analysis for one dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test_11\n",
    "train = train_11[1]\n",
    "clf = MajorityVoting(features_11)\n",
    "clf.fit(train, train['y'])\n",
    "display(clf.pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdisplay([train.head(), DataFrame(clf.predict(train)).head()], ['Data', 'Prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_error = sum(test['y'] != clf.predict(test)) / len(test) * 100\n",
    "training_error = sum(train['y'] != clf.predict(train)) / len(train) * 100\n",
    "print('Training error: {tr}% \\nTest error:     {te}%'.format(tr=round(training_error), te=round(test_error)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test_11\n",
    "train = train_11[1]\n",
    "clf = LogisticRegression(solver = 'lbfgs')\n",
    "clf.fit(train[features_11], train['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_error = sum(test['y'] != clf.predict(test[features_11])) / len(test) * 100\n",
    "training_error = sum(train['y'] != clf.predict(train[features_11])) / len(train) * 100\n",
    "print('Training error: {tr}% \\nTest error:     {te}%'.format(tr=round(training_error), te=round(test_error)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete analysis\n",
    "\n",
    "Lets generate multi-indexed key-value data frame for storing errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (combine_categories({'method': ['MV', 'LR'], 'size': sizes, 'type': ['test', 'train']})\n",
    "      .assign(error=np.nan, accuracy=np.nan))\n",
    "\n",
    "error = (pd.concat([\n",
    "         df.assign(source = '00', fit = 'bad',  dim = 'large'),\n",
    "         df.assign(source = '01', fit = 'good', dim = 'large'),\n",
    "         df.assign(source = '10', fit = 'bad',  dim = 'small'),\n",
    "         df.assign(source = '11', fit = 'good', dim = 'small')])\n",
    "         .set_index(['method', 'size', 'type', 'source']))[['dim', 'fit', 'error', 'accuracy']]\n",
    "\n",
    "error = error.sort_index()\n",
    "display(error.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate over all datasets and fill the table for majority voting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, size in enumerate(sizes):\n",
    "    test = test_00\n",
    "    train = train_00[i]\n",
    "    clf = MajorityVoting(features_00)\n",
    "    clf.fit(train, train['y'])\n",
    "    error.loc[('MV',size,'test' ,'00'), 'error'] = sum(test['y'] != clf.predict(test)) / len(test) * 100\n",
    "    error.loc[('MV',size,'train','00'), 'error'] = sum(train['y'] != clf.predict(train)) / len(train) * 100\n",
    "    \n",
    "    test = test_01\n",
    "    train = train_01[i]\n",
    "    clf = MajorityVoting(features_01)\n",
    "    clf.fit(train, train['y'])\n",
    "    error.loc[('MV',size,'test', '01'), 'error'] = sum(test['y'] != clf.predict(test)) / len(test) * 100\n",
    "    error.loc[('MV',size,'train','01'), 'error'] = sum(train['y'] != clf.predict(train)) / len(train) * 100\n",
    "\n",
    "    test = test_10\n",
    "    train = train_10[i]\n",
    "    clf = MajorityVoting(features_10)\n",
    "    clf.fit(train, train['y'])\n",
    "    error.loc[('MV',size,'test', '10'), 'error'] = sum(test['y'] != clf.predict(test)) / len(test) * 100\n",
    "    error.loc[('MV',size,'train','10'), 'error'] = sum(train['y'] != clf.predict(train)) / len(train) * 100\n",
    "\n",
    "    test = test_11\n",
    "    train = train_11[i]\n",
    "    clf = MajorityVoting(features_11)\n",
    "    clf.fit(train, train['y'])\n",
    "    error.loc[('MV',size,'test', '11'), 'error'] = sum(test['y'] != clf.predict(test)) / len(test) * 100\n",
    "    error.loc[('MV',size,'train','11'), 'error'] = sum(train['y'] != clf.predict(train)) / len(train) * 100\n",
    "\n",
    "display(error.loc['MV', 'error'].unstack())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, size in enumerate(sizes):\n",
    "    test = test_00\n",
    "    train = train_00[i]\n",
    "    features = features_00 \n",
    "    clf = LogisticRegression(solver = 'lbfgs')\n",
    "    clf.fit(train[features], train['y'])  \n",
    "    error.loc[('LR',size,'test', '00'), 'error'] = sum(test['y'] != clf.predict(test[features])) / len(test) * 100\n",
    "    error.loc[('LR',size,'train','00'), 'error'] = sum(train['y'] != clf.predict(train[features])) / len(train) * 100\n",
    "\n",
    "    test = test_01\n",
    "    train = train_01[i]\n",
    "    features = features_01 \n",
    "    clf = LogisticRegression(solver = 'lbfgs')\n",
    "    clf.fit(train[features], train['y'])    \n",
    "    error.loc[('LR',size,'test', '01'), 'error'] = sum(test['y'] != clf.predict(test[features])) / len(test) * 100\n",
    "    error.loc[('LR',size,'train','01'), 'error'] = sum(train['y'] != clf.predict(train[features])) / len(train) * 100\n",
    "\n",
    "    test = test_10\n",
    "    train = train_10[i]\n",
    "    features = features_10 \n",
    "    clf = LogisticRegression(solver = 'lbfgs')\n",
    "    clf.fit(train[features], train['y'])    \n",
    "    error.loc[('LR',size,'test', '10'), 'error'] = sum(test['y'] != clf.predict(test[features])) / len(test) * 100\n",
    "    error.loc[('LR',size,'train','10'), 'error'] = sum(train['y'] != clf.predict(train[features])) / len(train) * 100\n",
    "\n",
    "    test = test_11\n",
    "    train = train_11[i]\n",
    "    features = features_11 \n",
    "    clf = LogisticRegression(solver = 'lbfgs')\n",
    "    clf.fit(train[features], train['y'])    \n",
    "    error.loc[('LR',size,'test', '11'), 'error'] = sum(test['y'] != clf.predict(test[features])) / len(test) * 100\n",
    "    error.loc[('LR',size,'train','11'), 'error'] = sum(train['y'] != clf.predict(train[features])) / len(train) * 100\n",
    "\n",
    "display(error.loc['LR', 'error'].unstack())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add accuracy for clarity and save the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = error.assign(error = lambda df: round(df['error'], 2), accuracy = lambda df: round(100 - df['error'], 2)).reset_index()\n",
    "error.to_csv('results/convergence.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display results\n",
    "\n",
    "We plot two graphs, one for large-scale asymptotic behaviour and one for small-scale behaviour:\n",
    "\n",
    "* the first shows overall convergence\n",
    "* the second shows what happens in the beginning\n",
    "\n",
    "To make our life easier, we use `ggplot` grammar of graphics for specifying what we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotnine import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order facet dimensions\n",
    "from pandas.api.types import CategoricalDtype\n",
    "DimType = CategoricalDtype(['small', 'large'], ordered = True)\n",
    "FitType = CategoricalDtype(['good', 'bad'], ordered = True)\n",
    "df = error.assign(fit = error['fit'].astype(FitType), dim = error['dim'].astype(DimType))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Large-scale plot\n",
    "p = ggplot(data = df.loc[error['size'].isin([10, 1000, 2000, 3000, 4000, 5000]),:])\n",
    "p = p + geom_line(aes(x='size', y='accuracy', linetype='method', color='type'))\n",
    "p = p + geom_point(aes(x='size', y='accuracy', shape='method', color='type'), fill = 'white')\n",
    "p = p + facet_grid(['fit', 'dim'])\n",
    "p = p + scale_shape_manual(name='Method',values=['o', 's'], labels=['LR','MV'])\n",
    "p = p + scale_linetype_manual(name = 'Method', values=['-', '-.'], labels=['LR','MV']) \n",
    "p = p + scale_color_manual(name='Error type',   values=['orange', 'blue'])\n",
    "p.save('convergence-large.pdf', path='results', height=6, width=12, verbose=False)\n",
    "display(p)\n",
    "\n",
    "# Small-scale plot\n",
    "p = ggplot(data = df.loc[error['size'] <= 1000,:])\n",
    "p = p + geom_line(aes(x='size', y='accuracy', linetype='method', color='type'))\n",
    "p = p + geom_point(aes(x='size', y='accuracy', shape='method', color='type'), fill = 'white')\n",
    "p = p + facet_grid(['fit', 'dim'])\n",
    "p = p + scale_shape_manual(name='Method',values=['o', 's'], labels=['LR','MV'])\n",
    "p = p + scale_linetype_manual(name = 'Method', values=['-', '-.'], labels=['LR','MV']) \n",
    "p = p + scale_color_manual(name='Error type',   values=['orange', 'blue'])\n",
    "p.save('convergence-small.pdf', path='results', height=6, width=12, verbose=False)\n",
    "display(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Classifier that minimises empirical risk (<font color='red'>1p</font>)\n",
    "\n",
    "Given enough information about future data samples, it is possible to find a class with optimal accuracy.\n",
    "The corresponding construction `MajorityVoting` was given above for the binary classification task.\n",
    "* Extend the solution for multi-label classification task and apply it to the data frame `data` below.\n",
    "* Predict `z` for  `x` and `y` and show the corresponding table of rules.\n",
    "* What is the corresponding risk if it is defined as the probability of misclassification on `data`? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (DataFrame([(0, 0, 0), (0, 0, 1), (0, 0, 1), (0, 1, 2), (0, 1, 2),\n",
    "                  (1, 0, 1), (1, 0, 0), (1, 0, 2), (2, 0, 1), \n",
    "                  (2, 1, 0), (2, 1, 0), (2, 1, 0), \n",
    "                  (3, 1, 1), (3, 1, 1), (3, 1, 1), (3, 1, 2)], columns = ['x', 'y', 'z'])\n",
    "        .sample(frac=1).reset_index(drop = True))\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Visualise statistical fluctuations (<font color='red'>1p</font>)\n",
    "\n",
    "The visualisations constructed above are built based on a single run where for each size we have sampled a single dataset form a data source (**distribution**). \n",
    "As such, the figure fails to capture the effect of statistical fluctuations, i.e. the effect of sampling to the results.\n",
    "* Modify the code of the experiment so that 10 experiments are done for each dataset size.\n",
    "* Show different scores in the graph and compute the average score line. For clarity you can do separate plots for majority voting and logistic regression.\n",
    "* Justify decisions you made in the experiment design and interpret obtained results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Optimise the data generation process* (<font color='red'>0.5p</font>)\n",
    "\n",
    "The data generation procedure is slow as it does not use `numpy` matrix operations.\n",
    "Fix this issue and measure the speedup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Theoretical analysis of majority voting* (<font color='red'>3p</font>) \n",
    "\n",
    "Explain why the training accuracy is so high for majority voting. \n",
    "You can give a theoretical answer or design an experiment to answer the following questions. \n",
    "You can consider the extreme case where the features $x_i$ and labels $y$ are sampled randomly. \n",
    "\n",
    "* Give a rough estimate how many samples are needed to arrive to the situation where training error is roughly the same as test error. \n",
    " \n",
    "* How does the sample size depend on the number of dimensions? \n",
    "* What changes if some feature values are more probable than the others? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
